{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23d6d06",
   "metadata": {},
   "source": [
    "# H2 - PROGRAMMING EXERCISES "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669326f7",
   "metadata": {},
   "source": [
    "## 1. Binary Classification on Text Data. \n",
    "\n",
    "In this problem, you will implement several machine learning techniques from the class to perform classification on text data. Throughout the problem, we will be working on the NLP with Disaster Tweets Kaggle competition, where the task is to predict whether or not a tweet is about a real disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae054d",
   "metadata": {},
   "source": [
    "### (a) Download the data. \n",
    "Download the training and test data from Kaggle, and answer the following questions: (1) how many training and test data points are there? and (2) what percentage of the training tweets are of real disasters, and what percentage is not? Note that the meaning of each column is explained in the data description on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9003348",
   "metadata": {},
   "source": [
    "<font color='blue'> Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da28420e",
   "metadata": {},
   "source": [
    "The train dataset encompasses 7613 datapoints, while the test set only 3623, which is a test-train split of roughly [68-32].\n",
    "The train dataset contains 3271 real disaster tweets (datapoints where target = 1), which accounts for the 43% of the dataset and 4342 (57%) are labelled as fake disasters instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f19cca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  7613\n",
      "Test dataset:  3263\n",
      "Real Disasters in Train dataset:  3271\n",
      "Non-Real Disasters in Train dataset:  4342\n"
     ]
    }
   ],
   "source": [
    "# imports .\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# load train and test datasets.\n",
    "raw_train = pd.read_csv('./data/train.csv')\n",
    "raw_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(\"Train dataset: \", len(raw_train))\n",
    "print(\"Test dataset: \", len(raw_test))\n",
    "print(\"Real Disasters in Train dataset: \", len(raw_train[raw_train[\"target\"] == 1.0]))\n",
    "print(\"Non-Real Disasters in Train dataset: \", len(raw_train[raw_train[\"target\"] == 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4290da0",
   "metadata": {},
   "source": [
    "### (b) Split the training data. \n",
    "Since we do not know the correct values of labels in the test data, we will split the training data from Kaggle into a training set and a development set (a development set is a held out subset of the labeled data that we set aside in order to fine-tune models, before evaluating the best model(s) on the test data). Randomly choose 70% of the data points in the training data as the training set, and the remaining 30% of the data as the\n",
    "development set. Throughout the rest of this problem we will keep these two sets fixed. The\n",
    "idea is that we will train different models on the training set, and compare their performance\n",
    "on the development set, in order to decide what to submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5e0c78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_val = train_test_split(raw_train, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c963e32",
   "metadata": {},
   "source": [
    "### (c) Preprocess the data.\n",
    "Since the data consists of tweets, they may contain significant amounts\n",
    "of noise and unprocessed content. You may or may not want to do one or all of the following.\n",
    "Explain the reasons for each of your decision (why or why not).\n",
    "- Convert all the words to lowercase.\n",
    "- Lemmatize all the words (i.e., convert every word to its root so that all of “running,” “run,”# and “runs” are converted to “run” and and all of “good,” “well,” “better,” and “best” are converted to “good”; this is easily done using nltk.stem).\n",
    "- Strip punctuation.\n",
    "- Strip the stop words, e.g., “the”, “and”, “or”.\n",
    "- Strip @ and urls. (It’s Twitter.)\n",
    "- Something else? Tell us about it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4aba6",
   "metadata": {},
   "source": [
    "<font color = \"blue\"> Pre-Processing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed915f70",
   "metadata": {},
   "source": [
    "In this session we heavily pre-processed the data in the \"text\" column, to remove all the gibberish, urls, hashtags, etc and leave nice lemmatized english words to maximize the efficiency and speed of the bag of words model.\n",
    "\n",
    "The steps we took to pre-process the data are the following:\n",
    "- Make the whole text lowercase: This is needed to standardize the text and match words in future steps in a case-insensitive manner.\n",
    "- Remove using Regex any '@', '#' or 'http(s)://' characters followed by any characters, hence removing any tag, hashtag or url included in the text.\n",
    "- Using Regex to only keep alphabetic lemmas, removing numbers, dates or non alphabetic characters.\n",
    "- Using WordNetLemmatizer.lemmatize to standardize words. We decided to use the lemmatizer twice to leverage both modes 'v' and 'n', which we noticed worked better to standardize verbs and plurals respectively (e.g. 'v' works for flooding -> flood, while 'n' works for years -> year)\n",
    "- Finally, we filtered out any words that are stop words (i.e. the, so, etc) since they do not convey any useful information. Then we filter out words not present in the \"corpus.words\" dictionary of words provided by nltk. We found that this method eliminates very few meaningful words which are not recognized, but helps a lot in filtering out a lot of jibberish included in the tweets. Finally we manually check not to include the word \"target\" as it would create a new column \"target\", which is the column name used for the feature to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6f353604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "Lem = WordNetLemmatizer()\n",
    "stop_words = stopwords.words(\"english\")\n",
    "english_words = set(words.words())\n",
    "\n",
    "def preprocessing_lambda(text):\n",
    "    # Make everything lowercase.\n",
    "    out_text = str(text).lower()\n",
    "    # Remove mentions, hashtags and urls.\n",
    "    out_text = re.sub(r\"(?:\\@|\\#|https?\\://)\\S+\", \"\", out_text)\n",
    "    # Keep alphabetic sequences only\n",
    "    out_text = re.sub(r'[^a-zA-Z]', ' ', out_text)\n",
    "    \n",
    "    # tokenize sentence\n",
    "    token_out = word_tokenize(out_text)\n",
    "    \n",
    "    \n",
    "    # Lemmatize words using both settings from nltk as:\n",
    "    # 'v' works for bombing -> bomb\n",
    "    # 'n' works for years-> year\n",
    "    out_text = \" \".join([Lem.lemmatize(Lem.lemmatize(w, 'v'), 'n') for w in token_out])\n",
    "\n",
    "    # Keep only words longer than two characters\n",
    "    # ignore stopwords and words that are not in the english vocabulary\n",
    "    token_out = [w for w in token_out if (not w in stop_words) and (w in english_words) \\\n",
    "                 and (len(w) > 2) and w != \"target\"]\n",
    "    \n",
    "    return \" \".join([w for w in token_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d461ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = pd.concat([df_train, df_val, raw_test])\n",
    "df_tot[\"text\"] = df_tot[\"text\"].apply(preprocessing_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0f2b8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val = df_tot.iloc[:len(df_train) + len(df_val), :].sort_index().reset_index()\n",
    "df_train = df_train_val.iloc[:len(df_train), :].reset_index()\n",
    "df_val = df_train_val.iloc[len(df_train):, :].reset_index()\n",
    "df_test = df_tot.iloc[len(df_train) + len(df_val):, :].sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb8fab",
   "metadata": {},
   "source": [
    "\n",
    "### (d) Bag of words model\n",
    "The next task is to extract features in order to represent each tweet using\n",
    "the binary “bag of words” model, as discussed in lectures. The idea is to build a vocabulary\n",
    "of the words appearing in the dataset, and then to represent each tweet by a feature vector\n",
    "x whose length is the same as the size of the vocabulary, where xi = 1 if the i’th vocabulary\n",
    "word appears in that tweet, and xi = 0 otherwise. In order to build the vocabulary, you should\n",
    "choose some threshold M, and only include words that appear in at least k different tweets;\n",
    "this is important both to avoid run-time and memory issues, and to avoid noisy/unreliable\n",
    "features that can hurt learning. Decide on an appropriate threshold M, and discuss how you\n",
    "made this decision. Then, build the bag of words feature vectors for both the training and\n",
    "development sets, and report the total number of features in these vectors.\n",
    "In order to construct these features, we suggest using the CountVectorizer class in sklearn. A\n",
    "couple of notes on using this function: (1) you should set the option “binary=True” in order to ensure that the feature vectors are binary; and (2) you can use the option “min_df=M” in order to only include in the vocabulary words that appear in at least M different tweets. Finally,\n",
    "make sure you fit CountVectorizer only once on your training set and use the same instance\n",
    "to process both your training and development sets (don’t refit it on your development set a\n",
    "second time).\n",
    "\n",
    "__Important__: at this point you should only be constructing feature vectors for each data point\n",
    "using the text in the “text” column. You should ignore the “keyword” and “location” columns\n",
    "for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9bb0b",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> Bag Of Words Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449193a",
   "metadata": {},
   "source": [
    "In the bag of words model we opted for M = 0.001 (keep words that appear in at least 0.1% of the tweets.\n",
    "We tuned this hyperparameter by looking at both the model results for training and valuation, and the computational time. \n",
    "\n",
    "The score on the valuation set kept increasing as we increased the number of grams considered, which is a clear indication that the model was increasing performance and not overfitting. Hence we stopped at M = 0.001 since we noticed that reducing it further started impacting the computational time of training more, without providing significant improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d01552c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of grams found:  1116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "M = 0.001\n",
    "\n",
    "count_vect = CountVectorizer(min_df = M, binary = True) \n",
    "count_matrix = count_vect.fit_transform(df_train['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "grams_identified = count_vect.get_feature_names_out()\n",
    "train_vect_features = pd.DataFrame(data=count_array, columns = grams_identified)\n",
    "df_train_vect = pd.concat([df_train, train_vect_features], axis = 1)\n",
    "print(\"Number of grams found: \", len(grams_identified))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "b3549df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = count_vect.transform(df_val['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "val_vect_features = pd.DataFrame(data = count_array, columns = grams_identified)\n",
    "\n",
    "df_val_vect = pd.concat([df_val, val_vect_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "77b2c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = count_vect.transform(df_test['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "test_vect_features = pd.DataFrame(data = count_array, columns = grams_identified)\n",
    "\n",
    "df_test_vect = pd.concat([df_test, test_vect_features], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b7dd3",
   "metadata": {},
   "source": [
    "### (e) Logistic regression\n",
    "In this question, we will be training logistic regression models using\n",
    "bag of words feature vectors obtained in part (d). We will use the F1-score as the evaluation\n",
    "metric.\n",
    "\n",
    "We use F 1-score because it gives a more comprehensive view of classifier performance than\n",
    "accuracy. For more information on this metric see F1-score.\n",
    "We ask you to train the following classifiers. We suggest using the LogisticRegression imple-\n",
    "mentation in sklearn ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69106b",
   "metadata": {},
   "source": [
    "#### i. Train a logistic regression model without regularization terms\n",
    "You will notice that the\n",
    "default sklearn logistic regression utilizes L2 regularization. You can turn off L2 regularization by changing the penalty parameter. Report the F1 score in your training and\n",
    "in your development set. Comment on whether you observe any issues with overfitting\n",
    "or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61a37f",
   "metadata": {},
   "source": [
    "<font color='blue'> Overfitting/Underfitting Concerns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa69a07",
   "metadata": {},
   "source": [
    "At a first glance it seems that the model is not generalizing well on the Validation set while obtaining good results on the train dataset, which would hint to some degree of Overfitting.\n",
    "\n",
    "However, if case the model was actually overfitting, increasing the max_iter parameter to achieve better convergence should result in an even poorer performance on the validation set. We tried to increase the max_iter count up to 1500 and the performance on validation gets better, hence the model is not actually overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c368f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_vect.iloc[:, len(df_train.columns):]\n",
    "Y_train = df_train_vect[\"target\"]\n",
    "X_val = df_val_vect.iloc[:, len(df_val.columns):]\n",
    "Y_val = df_val_vect[\"target\"]\n",
    "X_test = df_test_vect.iloc[:, len(df_test.columns):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d0a7b42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-36 {color: black;background-color: white;}#sk-container-id-36 pre{padding: 0;}#sk-container-id-36 div.sk-toggleable {background-color: white;}#sk-container-id-36 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-36 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-36 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-36 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-36 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-36 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-36 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-36 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-36 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-36 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-36 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-36 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-36 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-36 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-36 div.sk-item {position: relative;z-index: 1;}#sk-container-id-36 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-36 div.sk-item::before, #sk-container-id-36 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-36 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-36 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-36 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-36 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-36 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-36 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-36 div.sk-label-container {text-align: center;}#sk-container-id-36 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-36 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-36\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;none&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" checked><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;none&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, penalty='none')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regr_none = LogisticRegression(penalty = \"none\", max_iter = 1000)\n",
    "logistic_regr_none.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "7306a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train_preds = logistic_regr_none.predict(X_train)\n",
    "train_F1_none = f1_score(Y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "98b2974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 None:  0.8252516010978957 \tVal F1 None:  0.6097186700767263\n"
     ]
    }
   ],
   "source": [
    "val_preds = logistic_regr_none.predict(X_val)\n",
    "val_F1_none = f1_score(Y_val, val_preds)\n",
    "print(\"Train F1 None: \", train_F1_none, \"\\tVal F1 None: \", val_F1_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd7236",
   "metadata": {},
   "source": [
    "#### ii. Train a logistic regression model with L1 regularization\n",
    "Sklearn provides some good\n",
    "examples for implementation. Report the performance on both the training and the\n",
    "development sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "1de2b8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:  10 \tTrain F1 L1:  0.8233117483811286 \tVal F1 L1:  0.6070861977789529\n",
      "c:  1.0 \tTrain F1 L1:  0.7830052808449351 \tVal F1 L1:  0.5758477096966093\n",
      "c:  0.1 \tTrain F1 L1:  0.5261282660332541 \tVal F1 L1:  0.3\n"
     ]
    }
   ],
   "source": [
    "coeffs = [10, 1.0, 0.1]\n",
    "for c in coeffs:\n",
    "    logistic_regr_l1 = LogisticRegression(C = c, penalty = \"l1\", solver = \"liblinear\")\n",
    "    logistic_regr_l1.fit(X_train, Y_train)\n",
    "    \n",
    "    train_preds = logistic_regr_l1.predict(X_train)\n",
    "    val_preds = logistic_regr_l1.predict(X_val)   \n",
    "    \n",
    "    train_F1_l1 = f1_score(Y_train, train_preds)\n",
    "    val_F1_l1 = f1_score(Y_val, val_preds)\n",
    "\n",
    "    print(\"c: \", c, \"\\tTrain F1 L1: \", train_F1_l1, \"\\tVal F1 L1: \", val_F1_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc41509",
   "metadata": {},
   "source": [
    "#### iii. Similarly, train a logistic regression model with L2 regularization \n",
    "Report the performance on the training and the development sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ccaa2055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-37 {color: black;background-color: white;}#sk-container-id-37 pre{padding: 0;}#sk-container-id-37 div.sk-toggleable {background-color: white;}#sk-container-id-37 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-37 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-37 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-37 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-37 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-37 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-37 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-37 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-37 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-37 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-37 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-37 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-37 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-37 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-37 div.sk-item {position: relative;z-index: 1;}#sk-container-id-37 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-37 div.sk-item::before, #sk-container-id-37 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-37 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-37 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-37 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-37 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-37 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-37 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-37 div.sk-label-container {text-align: center;}#sk-container-id-37 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-37 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-37\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" checked><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regr_l2 = LogisticRegression()\n",
    "logistic_regr_l2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "4d8a78b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 L2:  0.7926944971537002 \tVal F1 L2:  0.6017391304347827\n"
     ]
    }
   ],
   "source": [
    "train_preds = logistic_regr_l2.predict(X_train)\n",
    "train_F1_l2 = f1_score(Y_train, train_preds)\n",
    "\n",
    "val_preds = logistic_regr_l2.predict(X_val)\n",
    "val_F1_l2 = f1_score(Y_val, val_preds)\n",
    "\n",
    "print(\"Train F1 L2: \", train_F1_l2, \"\\tVal F1 L2: \", val_F1_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c8d5ca",
   "metadata": {},
   "source": [
    "#### iv. Which one of the three classifiers performed the best on your training and development set? \n",
    "Did you observe any overfitting and did regularization help reduce it? Support your answers with the classifier performance you got.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b1069",
   "metadata": {},
   "source": [
    "<font color='blue'> Best Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64097f",
   "metadata": {},
   "source": [
    "For L1 regularization, I tried three models with coefficient 10, 1 and 0.1 respectively.\n",
    "C = 10 seems to significantly outperform the other two models, hence it will be the L1 model considered in further analysis.\n",
    "\n",
    "It seems that the non regularized model very slightly outperforms the L1 and L2 regularized models. \n",
    "The three models perform very similarly, which hints to the fact that there is no overfitting, hence L1 and L2 regression do not make any improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec5285",
   "metadata": {},
   "source": [
    "#### v. Inspect the weight vector of the classifier with L1 regularization (in other words, look at the θ you got after training)\n",
    "You can access the weight vector of the trained model using the coef_ attribute of a LogisticRegression instance. What are the most important words for deciding whether a tweet is about a real disaster or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e674f24",
   "metadata": {},
   "source": [
    "<font color='blue'> L1 regularization top words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a3d6f",
   "metadata": {},
   "source": [
    "It looks like the 10 most important words found by L1 all describe objects or events strongly connected to a disastrous scenario: debris, atomic, spill, train, outbreak, fire, derailment, storm, accident and mass.\n",
    "\n",
    "This shows both that the model is correct in identifying insightful words in the \"disasters dictionary\" as well as that the pre-processing did a great job at getting rid of all the non-important words that the model could have mistakenly considered as important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a3bd9af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  debris           L1 Coefficient:  1.6307\n",
      "Word:  atomic           L1 Coefficient:  1.4876\n",
      "Word:  spill            L1 Coefficient:  1.4407\n",
      "Word:  train            L1 Coefficient:  1.1221\n",
      "Word:  outbreak         L1 Coefficient:  1.0948\n",
      "Word:  fire             L1 Coefficient:  1.0553\n",
      "Word:  derailment       L1 Coefficient:  1.0479\n",
      "Word:  storm            L1 Coefficient:  0.8163\n",
      "Word:  accident         L1 Coefficient:  0.7453\n",
      "Word:  mass             L1 Coefficient:  0.729\n"
     ]
    }
   ],
   "source": [
    "l1_coeffs = np.array(logistic_regr_l1.coef_[0])\n",
    "\n",
    "n = 10\n",
    "idx = np.argpartition(l1_coeffs, -n)[-n:]\n",
    "indices = idx[np.argsort((-l1_coeffs)[idx])]\n",
    "\n",
    "for c, w in zip(l1_coeffs[indices], X_train.columns[indices]):\n",
    "    print(\"Word: \", w, \" \" * (15 - len(w)), \"L1 Coefficient: \", round(c, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aed40e",
   "metadata": {},
   "source": [
    "### (f) Bernoulli Naive Bayes\n",
    "Implement a Bernoulli Naive Bayes classifier to predict the probability of whether each tweet is about a real disaster. Train this classifier on the training set, and report its F1-score on the development set.\n",
    "\n",
    "__Important__: For this question you should implement the classifier yourself similar to what\n",
    "was shown in class, without using any existing machine learning libraries such as sklearn.\n",
    "You may only use basic libraries such as numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "eb2a2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myBernoulliNB(object):\n",
    "    def __init__(self, alpha = 1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        n, d  = X.shape\n",
    "\n",
    "        K = 2 # Binary classes = 2\n",
    "\n",
    "        self.psis = np.zeros([K, d])\n",
    "        self.phis = np.zeros([K])\n",
    "\n",
    "        for k in range(K):\n",
    "            X_l = X[Y == k]\n",
    "            \n",
    "            self.psis[k] = (np.sum(X_l, axis = 0) + self.alpha) / (np.sum(X_l) + 2 * self.alpha)\n",
    "            self.phis[k] = X_l.shape[0] / float(n)\n",
    "        \n",
    "        self.psis = np.reshape(self.psis, (K, 1, d))\n",
    "        self.psis = self.psis.clip(1e-14, 1-1e-14)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        n, d = X.shape\n",
    "        X = np.reshape(X, (1, n, d))\n",
    " \n",
    "        logpy = np.log(self.phis).reshape([K, 1])\n",
    "        logpxy = X * np.log(self.psis) + (1 - X) * np.log(1 - self.psis)\n",
    "        logpyx = logpxy.sum(axis = 2) + logpy\n",
    "        return logpyx.argmax(axis = 0).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81493388",
   "metadata": {},
   "source": [
    "As you work on this problem, you may find that some words in the vocabulary occur in the\n",
    "development set but are not in the training set. As a result, the standard Naive Bayes model\n",
    "learns to assign them an occurrence probability of zero, which becomes problematic when\n",
    "we observe this \"zero probability\" event on our development set.\n",
    "The solution to this problem is a form of regularization called Laplace smoothing or additive\n",
    "smoothing. The idea is to use \"pseudo-counts\", i.e. to increment the number of times we\n",
    "have seen each word or document by some number of \"virtual\" occurrences α. Thus, the\n",
    "Naive Bayes model will behave as if every word or document has been seen at least α times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "0aed92ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 BernoulliNB:  0.7655061102144339 \tVal F1 BernoulliNB:  0.6568421052631579\n"
     ]
    }
   ],
   "source": [
    "BNB_nosmoothing = myBernoulliNB(alpha = 1)\n",
    "\n",
    "BNB_nosmoothing.fit(x_train_numpy, y_train_numpy)\n",
    "bnb_nosmoothing_train_preds = BNB_nosmoothing.predict(x_train_numpy)\n",
    "bnb_nosmoothing_val_preds = BNB_nosmoothing.predict(X_val.to_numpy())\n",
    "\n",
    "\n",
    "F1_BNB_train = f1_score(Y_train, bnb_nosmoothing_train_preds)\n",
    "F1_BNB_val = f1_score(Y_val, bnb_nosmoothing_val_preds)\n",
    "print(\"Train F1 BernoulliNB: \", F1_BNB_train, \"\\tVal F1 BernoulliNB: \", F1_BNB_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d477b",
   "metadata": {},
   "source": [
    "### (g) Model comparison\n",
    "You just implemented a generative classifier and a discriminative classifier. Reflect on the following:\n",
    "- Which model performed the best in predicting whether a tweet is of a real disaster or not? Include your performance metric in your response. Comment on the pros and cons of using generative vs discriminative models.\n",
    "- Think about the assumptions that Naive Bayes makes. How are the assumptions different from logistic regressions? Discuss whether it’s valid and efficient to use Bernoulli Naive Bayes classifier for natural language texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcd9b3",
   "metadata": {},
   "source": [
    "<font color='blue'> Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45d615",
   "metadata": {},
   "source": [
    "The BernoulliNB model seems to outperform other modules on generalizing to the validation set (F1 = 0.657), while L1, L2 and None regularization obtain very similar F1 Scores (0.605).\n",
    "\n",
    "Generative models like Bernoulli Naive Bayes are less computational expensive (we could see in this exercise that Logistic Regression starts to be slow for large \"max_iter\" values) and generally better when there is a limited amount of data. Instead, Discriminative algorithms like Logistic Regression are more robust against outliers.\n",
    "\n",
    "A key difference between generative and discriminative models is that generative models assume independence among predictors, while discriminative models don't.\n",
    "This key difference seems to be the reason why BernoulliNB performs better on the development set (i.e. generalizes better to unseen datapoints) but actually achieves a significantly lower score for training.\n",
    "\n",
    "In comparing the models, we must also notice that the scores we also must notice that the heavy pre-processing approach we opted for has great impact on the general performance of the models, which would be significantly higher with less pre-processing steps. However, for the sake of approaching the NLP task in the most logical way we felt that the reduction in data size produced by the extra data-processing steps is more valuable in a real prediction scenario than brute forcing bag-of-words on more raw tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe35df",
   "metadata": {},
   "source": [
    "### (h) N-gram model\n",
    "The N-gram model is similar to the bag of words model, but instead of using\n",
    "individual words we use N-grams, which are contiguous sequences of words. For example,\n",
    "using N = 2, we would says that the text “Alice fell down the rabbit hole” consists of the sequence of 2-grams: [\"Alice fell\", \"fell down\", \"down the\", \"the rabbit\", \"rabbit hole\"], and the\n",
    "following sequence of 1-grams: [\"Alice\", \"fell\", \"down\", \"the\", \"rabbit\", \"hole\"]. All eleven\n",
    "of these symbols may be included in the vocabulary, and the feature vector x is defined according to xi = 1 if the i’th vocabulary symbol occurs in the tweet, and xi = 0 otherwise.\n",
    "Using N = 2, construct feature representations of the tweets in the training and development tweets. Again, you should choose a threshold M, and only include symbols in the vocabulary\n",
    "that occur in at least M different tweets in the training set. Discuss how you chose the threshold M, and report the total number of 1-grams and 2-grams in your vocabulary. In addition,\n",
    "take 10 2-grams from your vocabulary, and print them out.\n",
    "\n",
    "Then, implement a logistic regression and a Bernoulli classifier to train on 2-grams. You may\n",
    "reuse the code in (e) and (f). You may also choose to use or not use a regularization term,\n",
    "depending on what you got from (e). Report your results on training and development set.\n",
    "Do these results differ significantly from those using the bag of words model? Discuss what\n",
    "this implies about the task.\n",
    "\n",
    "Again, we suggest using CountVectorizer to construct these features. In order to include both\n",
    "1-gram and 2-gram features, you can set ngram_range=(1,2). Note also that in this case,\n",
    "since there are probably many different 2-grams in the dataset, it is especially important carefully set min_df in order to avoid run-time and memory issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d73ea",
   "metadata": {},
   "source": [
    "<font color='blue'> 2-grams Only Considerations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d0b88",
   "metadata": {},
   "source": [
    "Only using 2grams results in a very underfitted model.\n",
    "Firstly we had to drop the value of M significantly, to account for the fact that 2grams are generally less likely to appear in multiple tweets.\n",
    "After tuning M to generate a similar number of grams that we got for 1-grams, we trained the model and observed the results. The F1-score on the Validation set is incredibly low: (0.15). That was expected as it is more difficult for 2grams found in the train set to appear many times in the validation set too, so probably most features do not convey much information. \n",
    "\n",
    "Furthermore, we heavily preprocessed the data. Training a 2-gram model on less processed data (for example not filtering out stopwords) would likely perform way better, since one stop word and a disaster term could combine together to create insightful 2grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fc0dc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 0.0004\n",
    "twogram_vect = CountVectorizer(min_df = M, binary = True, ngram_range = (2, 2)) \n",
    "count_matrix = twogram_vect.fit_transform(df_train['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "grams_identified = twogram_vect.get_feature_names_out()\n",
    "train_twogram_vect_features = pd.DataFrame(data=count_array, columns = grams_identified)\n",
    "\n",
    "df_train_twogram_vect = pd.concat([df_train, train_twogram_vect_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "78a34db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = twogram_vect.transform(df_val['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "val_twogram_vect_features = pd.DataFrame(data = count_array, columns = twogram_vect.get_feature_names_out())\n",
    "\n",
    "df_val_twogram_vect = pd.concat([df_val, val_twogram_vect_features], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6f870f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two grams count over total grams count:  946 / 946\n"
     ]
    }
   ],
   "source": [
    "twograms = list(filter(lambda x : \" \" in x, grams_identified))\n",
    "print(\"two grams count over total grams count: \", len(twograms), \"/\", len(grams_identified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "28ab35bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned aircraft', 'access top', 'accident man', 'accident property', 'active exploit', 'added video', 'affected fatal', 'ago today', 'air accident', 'air ambulance']\n"
     ]
    }
   ],
   "source": [
    "print(twograms[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c58ddec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_twogram_vect.iloc[:, len(df_train.columns):]\n",
    "Y_train = df_train_twogram_vect[\"target\"]\n",
    "X_val = df_val_twogram_vect.iloc[:, len(df_val.columns):]\n",
    "Y_val = df_val_twogram_vect[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f94f9395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regr_l2 = LogisticRegression(solver = \"liblinear\")\n",
    "logistic_regr_l2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6bb8ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 L2:  0.5606617647058824 \tVal F1 L2:  0.12730627306273065\n"
     ]
    }
   ],
   "source": [
    "train_preds = logistic_regr_l2.predict(X_train)\n",
    "train_F1_l2 = f1_score(Y_train, train_preds)\n",
    "\n",
    "val_preds = logistic_regr_l2.predict(X_val)\n",
    "val_F1_l2 = f1_score(Y_val, val_preds)\n",
    "\n",
    "print(\"Train F1 L2: \", train_F1_l2, \"\\tVal F1 L2: \", val_F1_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6299772",
   "metadata": {},
   "source": [
    "<font color='blue'> Combined 1-grams and 2-grams Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec34764",
   "metadata": {},
   "source": [
    "We now used both 1-grams and 2-grams (i.e. set the range to (1,2)).\n",
    "This allows the model to train on insightful 1grams as well as common 2-grams. \n",
    "This does improve the performance of the 1-gram L2 regularized LinearRegression model very slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "35ef5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two grams count over total grams count:  275 / 1391\n"
     ]
    }
   ],
   "source": [
    "M = 0.001\n",
    "twogram_vect = CountVectorizer(min_df = M, binary = True, ngram_range = (1, 2)) \n",
    "count_matrix = twogram_vect.fit_transform(df_train['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "grams_identified = twogram_vect.get_feature_names_out()\n",
    "train_twogram_vect_features = pd.DataFrame(data=count_array, columns = grams_identified)\n",
    "\n",
    "df_train_twogram_vect = pd.concat([df_train, train_twogram_vect_features], axis = 1)\n",
    "\n",
    "count_matrix = twogram_vect.transform(df_val['text'])\n",
    "count_array = count_matrix.toarray()\n",
    "\n",
    "val_twogram_vect_features = pd.DataFrame(data = count_array, columns = twogram_vect.get_feature_names_out())\n",
    "\n",
    "df_val_twogram_vect = pd.concat([df_val, val_twogram_vect_features], axis = 1)\n",
    "\n",
    "twograms = list(filter(lambda x : \" \" in x, grams_identified))\n",
    "print(\"two grams count over total grams count: \", len(twograms), \"/\", len(grams_identified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6b16b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned aircraft', 'added video', 'affected fatal', 'air accident', 'air ambulance', 'aircraft debris', 'airplane accident', 'airplane debris', 'ambulance helicopter', 'amid crisis']\n"
     ]
    }
   ],
   "source": [
    "print(twograms[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8ade9bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train_twogram_vect.iloc[:, len(df_train.columns):]\n",
    "Y_train = df_train_twogram_vect[\"target\"]\n",
    "X_val = df_val_twogram_vect.iloc[:, len(df_val.columns):]\n",
    "Y_val = df_val_twogram_vect[\"target\"]\n",
    "\n",
    "logistic_regr_l2 = LogisticRegression(solver = \"liblinear\")\n",
    "logistic_regr_l2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c9ae6b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 L2:  0.801909307875895 \tVal F1 L2:  0.6062717770034843\n"
     ]
    }
   ],
   "source": [
    "train_preds = logistic_regr_l2.predict(X_train)\n",
    "train_F1_l2 = f1_score(Y_train, train_preds)\n",
    "\n",
    "val_preds = logistic_regr_l2.predict(X_val)\n",
    "val_F1_l2 = f1_score(Y_val, val_preds)\n",
    "\n",
    "print(\"Train F1 L2: \", train_F1_l2, \"\\tVal F1 L2: \", val_F1_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6529134",
   "metadata": {},
   "source": [
    "### (i) Determine performance with the test set \n",
    "Re-build your feature vectors and re-train your preferred classifier (either bag of word or n-gram using either logistic regression or Bernoulli naive bayes) using the entire Kaggle training data (i.e. using all of the data in both the training and development sets). Then, test it on the Kaggle test data. Submit your results to Kaggle,\n",
    "and report the resulting F1-score on the test data, as reported by Kaggle. Was this lower or\n",
    "higher than you expected? Discuss why it might be lower or higher than your expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca6b1c",
   "metadata": {},
   "source": [
    "<font color='blue'> Results on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457b19b",
   "metadata": {},
   "source": [
    "#### Kaggle Score: 0.72785\n",
    "\n",
    "The results obtained are better than what we expected given the performance of the model on the validation set. \n",
    "\n",
    "We think that might be because the heavy pre-processing that we opted for might have resulted in some important information being lost. By running the bag of words on unprocessed data, we noticed words like \"hiroshima\" and \"california\" being quite common and informative. However these words were lost in the pre-processing due to the \"english vocabulary\" filter. That might have caused the validation score to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4630cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BNB_nosmoothing = myBernoulliNB(alpha = 1)\n",
    "BNB_nosmoothing.fit(x_train_numpy, y_train_numpy)\n",
    "\n",
    "test_preds = BNB_nosmoothing.predict(X_test.to_numpy())\n",
    "# test_preds = logistic_regr_l2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c0928b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(columns = ['id', 'target'])\n",
    "pred_df[\"id\"] = df_tot.iloc[len(df_train) + len(df_val):, 0].sort_index()\n",
    "pred_df[\"target\"] = test_preds.astype(\"int\")\n",
    "\n",
    "pred_df.to_csv('./results/test_predictions.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1857c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
